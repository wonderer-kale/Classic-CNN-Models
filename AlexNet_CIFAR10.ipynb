{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (50000, 32, 32, 3)\n",
      "Shape of the testing set: (10000, 32, 32, 3)\n",
      "Ground truth label (training set): [[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [9]\n",
      " [1]\n",
      " [1]]\n",
      "Ground truth label (testing set): [[3]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [5]\n",
      " [1]\n",
      " [7]]\n",
      "Shape of the One-hot label: (50000, 10), (10000, 10)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "pooling_1 (MaxPooling2D)     (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "pooling_2 (MaxPooling2D)     (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "pooling_3 (MaxPooling2D)     (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fs_1 (Dense)                 (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fs_2 (Dense)                 (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "logit (Dense)                (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,012,682\n",
      "Trainable params: 4,012,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Validation accuracy: \n",
      "0.6365\n"
     ]
    }
   ],
   "source": [
    "# Import packages used in this script\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import keras\n",
    "\n",
    "## Data, can also load images from other places\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "## Build model, load model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "## Dense -> Fully Connected\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "## Activation functions\n",
    "from keras.layers import Dropout, LeakyReLU\n",
    "\n",
    "## Optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "## Callbacks --- Save Model (one of its parameters)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## Split whole dataset into two groups(training / validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Compute the accuracy score for the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Encode integer label into vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## Plot function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## Load mnist dataset, confirm the shape and the contents of the data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(\"Shape of the training set: {}\".format(x_train.shape))\n",
    "print(\"Shape of the testing set: {}\".format(x_test.shape))\n",
    "print(\"Ground truth label (training set): {}\".format(y_train))\n",
    "print(\"Ground truth label (testing set): {}\".format(y_test))\n",
    "\n",
    "## Normalize data in the range(0 ~ 1)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "## Encode integer label into one-hot vector\n",
    "## e.g. 3 -> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "## e.g. 5 -> [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "y_train = keras.utils.to_categorical(y_train.reshape(-1), 10)\n",
    "y_test = keras.utils.to_categorical(y_test.reshape(-1), 10)\n",
    "print(\"Shape of the One-hot label: {}, {}\".format(y_train.shape, y_test.shape))\n",
    "\n",
    "# Modified AlexNet\n",
    "model = Sequential()  ## build model graph\n",
    "\n",
    "## Add the convolution layer (named conv_1) to the graph\n",
    "## Filter size = 11 * 11, channel = 96, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(96, kernel_size = (11, 11), \n",
    "                 strides = (4, 4),\n",
    "                 input_shape = (32, 32, 3),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_1'))\n",
    "\n",
    "## Add the pooling layer (named pooling_1) to the graph\n",
    "## Filter size = 3* 3, stride = 2\n",
    "## Pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                       padding = 'same', name = 'pooling_1'))\n",
    "\n",
    "## Add the convolution layer (named conv_2) to the graph\n",
    "## Filter size = 5 * 5, channel = 256, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(256, kernel_size = (5, 5),\n",
    "                 strides = (1, 1),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_2'))\n",
    "\n",
    "## Add the pooling layer (named pooling_2) to the graph\n",
    "## Filter size = 3* 3, stride = 2\n",
    "## Pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                       padding = 'same', name = 'pooling_2'))\n",
    "\n",
    "## Add the convolution layer (named conv_3) to the graph\n",
    "## Filter size = 3* 3, channel = 384, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(384, kernel_size = (3, 3),\n",
    "                 strides = (1, 1),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_3'))\n",
    "\n",
    "## Add the convolution layer (named conv_4) to the graph\n",
    "## Filter size = 3* 3, channel = 384, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(384, kernel_size = (3, 3),\n",
    "                 strides = (1, 1),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_4'))\n",
    "\n",
    "## Add the convolution layer (named conv_5) to the graph\n",
    "## Filter size = 3* 3, channel = 384, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(256, kernel_size = (3, 3),\n",
    "                 strides = (1, 1),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_5'))\n",
    "\n",
    "## Add the pooling layer (named pooling_3) to the graph\n",
    "## Filter size = 3 * 3, stride = 2\n",
    "## Pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                       padding = 'same', name = 'pooling_3'))\n",
    "\n",
    "## Reshape the feature map into vectors\n",
    "model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "## Add the fully connected layer (named fs_1) to the graph\n",
    "## Units = 512, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "## Weight shape = (256, 512)\n",
    "model.add(Dense(512, activation = 'relu',\n",
    "                kernel_initializer = 'he_normal', name = 'fs_1'))\n",
    "\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "## Add the fully connected layer (named fs_2) to the graph\n",
    "## Units = 256, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "## Weight shape = (512, 256)\n",
    "model.add(Dense(256, activation = 'relu',\n",
    "                kernel_initializer = 'he_normal', name = 'fs_2'))\n",
    "\n",
    "## Add the output layer (named logit) to the graph\n",
    "## Units = 10, activation function = softmax (normalize)\n",
    "## Weight initializer following normal distribution\n",
    "## Weight shape = (256, 10)\n",
    "model.add(Dense(units = 10, activation = 'softmax',\n",
    "                kernel_initializer = 'he_normal', name = 'logit'))\n",
    "\n",
    "## Define the objection function and optimizer\n",
    "## Define the evaluation metrics: accuracy (for classification)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "## Print the detail of the model\n",
    "model.summary()\n",
    "\n",
    "'''\n",
    "## Training with data augmentation\n",
    "## *******************************\n",
    "datagen = ImageDataGenerator(rotation_range = 20,\n",
    "                            width_shift_range = 0.2,\n",
    "                            height_shift_range = 0.2,\n",
    "                            zoom_range = 0.2,\n",
    "                            shear_range = 0.2)\n",
    "datagen.fit(x_train)\n",
    "s = datagen.flow(x_train, y_train, batch_size = 256)\n",
    "history = model.fit_generator(s, steps_per_epoch = 100, epochs = 20,\n",
    "                             validation_data = (x_test, y_test),\n",
    "                             callbacks = [ModelCheckpoint('CIFAR10_sample_model.h5',\n",
    "                                                         monitor = 'val_accuracy',\n",
    "                                                         save_best_only = True)])\n",
    "\n",
    "### Train the whole model using \"fit\" function\n",
    "### Epoch: Number of training loops\n",
    "### Shuffle: perturb order of the training data\n",
    "### Save the model (named Cifar10_sample_model.h5)\n",
    "### Save the model only when the testing accuracy achieves the best\n",
    "history = model.fit(x_train, y_train, epochs = 20, \n",
    "                    validation_data = (x_test, y_test),\n",
    "                    shuffle = True, batch_size = 256, \n",
    "                    callbacks = [ModelCheckpoint('CIFAR10_sample_model.h5',\n",
    "                                                 monitor = 'val_accuracy',\n",
    "                                                 save_best_only = True)])\n",
    "'''\n",
    "model_test = load_model('CIFAR10_sample_model.h5') \n",
    "\n",
    "### Plot testing data\n",
    "def plot(a):\n",
    "    '''\n",
    "    Multiply 255 to the normalized data\n",
    "    and transform the data type from float into int\n",
    "    '''\n",
    "    a *= 255\n",
    "    a = a.astype(np.uint8)\n",
    "    return a.reshape(32, 32, 3)\n",
    "\n",
    "# ********** Display testing images **********\n",
    "#print(\"n = \", end = '')\n",
    "#n = int(input())\n",
    "#ax = plt.subplot(1, 1, 1)\n",
    "#plt.imshow(plot(x_test[n]), cmap = 'gray')\n",
    "#ax.get_xaxis().set_visible(False)\n",
    "#ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "# Build category dictionary\n",
    "category = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "    \n",
    "### Print inference results corresponding to the images we plot\n",
    "#prediction = model_test.predict(x_test[n].reshape(-1, 32, 32, 3))\n",
    "#print(\"Inference label: {}\".format(category[np.argmax(prediction, axis = 1)[0]]))\n",
    "#print(\"Ground truth label: {}\".format(category[np.argmax(y_test[n], axis = 0)])) \n",
    "    # y_test[n] is one-hot-encoded, use np.argmax to decode\n",
    "    \n",
    "pred = model_test.predict(x_test.reshape(-1, 32, 32, 3))\n",
    "predd = np.argmax(pred, axis = 1)\n",
    "ans = np.argmax(y_test, axis = 1)\n",
    "sum = 0\n",
    "for i in range(10000):\n",
    "    if predd[i] == ans[i]:\n",
    "        sum += 1\n",
    "accuracy = sum / 10000\n",
    "print(\"Validation accuracy: \")\n",
    "print(accuracy)\n",
    "    \n",
    "# parameters: 4,012,682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
