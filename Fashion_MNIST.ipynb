{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (60000, 28, 28)\n",
      "Shape of the testing set: (10000, 28, 28)\n",
      "Ground truth label (training set): [9 0 0 ... 3 0 5]\n",
      "Ground truth label (testing set): [9 2 1 ... 8 1 5]\n",
      "Shape of the training dataset: (60000, 28, 28, 1)\n",
      "Shape of the testing dataset: (10000, 28, 28, 1)\n",
      "One-hot label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Shape of the One-hot label: (60000, 10), (10000, 10)\n",
      "n = 2\n",
      "Inference label: Trousers\n",
      "Ground truth label: Trousers\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages used in this script\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import keras\n",
    "\n",
    "## Data, can also load images from other places\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "## Build model, load model\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "## Dense -> Fully Connected\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "## Activation functions\n",
    "from keras.layers import Dropout, LeakyReLU\n",
    "\n",
    "## Optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "## Callbacks --- Save Model (one of its parameters)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## Split whole dataset into two groups(training / validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Compute the accuracy score for the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## Encode integer label into vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## Plot function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## Load mnist dataset, confirm the shape and the contents of the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"Shape of the training set: {}\".format(x_train.shape))\n",
    "print(\"Shape of the testing set: {}\".format(x_test.shape))\n",
    "print(\"Ground truth label (training set): {}\".format(y_train))\n",
    "print(\"Ground truth label (testing set): {}\".format(y_test))\n",
    "\n",
    "## Reshape data whilst normalizing the data in the range(0 ~ 1)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255\n",
    "print(\"Shape of the training dataset: {}\".format(x_train.shape))\n",
    "## Reshape data whilst normalizing the data in the range(0 ~ 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255\n",
    "print(\"Shape of the testing dataset: {}\".format(x_test.shape))\n",
    "\n",
    "## Encode integer label into one-hot vector\n",
    "## e.g. 3 -> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "## e.g. 5 -> [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print(\"One-hot label: {}\".format(y_test[0]))\n",
    "print(\"Shape of the One-hot label: {}, {}\".format(y_train.shape, y_test.shape))\n",
    "'''\n",
    "# Modified LeNet\n",
    "model = Sequential()  ## build model graph\n",
    "\n",
    "## Add the convolution layer (named conv_1) to the graph\n",
    "## Filter size = 3 * 3, channel = 128, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), strides = 1,\n",
    "                 input_shape = (28, 28, 1),\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_1'))\n",
    "\n",
    "## Add the pooling layer (named pooling_1) to the graph\n",
    "## Filter size = 2 * 2, stride = 2\n",
    "## Not pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D((2, 2), strides = 2, padding = 'valid',\n",
    "                       name = 'pooling_1'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Add the convolution layer (named conv_2) to the graph\n",
    "## Filter size = 3 * 3, channel = 256, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), strides = 1,\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_2'))\n",
    "\n",
    "## Add the pooling layer (named pooling_2) to the graph\n",
    "## Filter size = 2 * 2, stride = 2\n",
    "## Not pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D((2, 2), strides = 2, padding = 'valid',\n",
    "                       name = 'pooling_2'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Add the convolution layer (named conv_3) to the graph\n",
    "## Filter size = 3 * 3, channel = 512, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), strides = 1,\n",
    "                 padding = 'same', activation = 'relu',\n",
    "                 kernel_initializer = 'he_normal', name = 'conv_3'))\n",
    "\n",
    "## Add the pooling layer (named pooling_3) to the graph\n",
    "## Filter size = 2 * 2, stride = 2\n",
    "## Not pad zero to the feature map boundary\n",
    "model.add(MaxPooling2D((2, 2), strides = 2, padding = 'valid',\n",
    "                       name = 'pooling_3'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Reshape the feature map into vectors\n",
    "model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "## Add the fully connected layer (named fs_1) to the graph\n",
    "## Units = 120, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Dense(512, activation = 'relu',\n",
    "                kernel_initializer = 'he_normal', name = 'fs_1'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Add the fully connected layer (named fs_2) to the graph\n",
    "## Units = 84, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Dense(256, activation = 'relu',\n",
    "                kernel_initializer = 'he_normal', name = 'fs_2'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Add the fully connected layer (named fs_2) to the graph\n",
    "## Units = 128, activation function = relu\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Dense(128, activation = 'relu',\n",
    "                kernel_initializer = 'he_normal', name = 'fs_3'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "## Add the output layer (named logit) to the graph\n",
    "## Units = 10, activation function = softmax(normalize)\n",
    "## Weight initializer following normal distribution\n",
    "model.add(Dense(units = 10, activation = 'softmax',\n",
    "                kernel_initializer = 'he_normal', name = 'logit'))\n",
    "\n",
    "## Define the objection function and optimizer\n",
    "## Define the evaluation metrics: accuracy (for classification)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "## Print the detail of the model\n",
    "model.summary()\n",
    "\n",
    "## Training with data augmentation\n",
    "## *******************************\n",
    "datagen = ImageDataGenerator(rotation_range = 20,\n",
    "                width_shift_range = 0.2,\n",
    "                height_shift_range = 0.2,\n",
    "                zoom_range = 0.2, \n",
    "                shear_range = 0.2)\n",
    "datagen.fit(x_train)\n",
    "s = datagen.flow(x_train, y_train, batch_size = 256)\n",
    "history = model.fit_generator(s, steps_per_epoch = 100, epochs = 20,\n",
    "                             validation_data = (x_test, y_test),\n",
    "                             callbacks = [ModelCheckpoint('Fashion_MNIST_model.h5',\n",
    "                                             monitor = 'val_accuracy',\n",
    "                                             save_best_only = True)])\n",
    "\n",
    "### Train the whole model using \"fit\" function\n",
    "### Epoch: Number of training loops\n",
    "### Shuffle: perturb order of the training data\n",
    "### Save the model (named MNIST_Project_model.h5)\n",
    "### Save the model only when the testing accuracy achieves the best\n",
    "history = model.fit(x_train, y_train, epochs = 20, \n",
    "                    validation_data = (x_test, y_test),\n",
    "                    shuffle = True, batch_size = 100, \n",
    "                    callbacks = [ModelCheckpoint('Fashion_MNIST_model.h5',\n",
    "                                    monitor = 'val_accuracy',\n",
    "                                    save_best_only = True)])\n",
    "'''\n",
    "model_test = load_model('Fashion_MNIST_model.h5') \n",
    "\n",
    "### Plot testing data\n",
    "def plot(a):\n",
    "    ## Multiply 255 to the normalized data and transform the data type from float into int\n",
    "    a *= 255\n",
    "    a = a.astype(np.uint8)\n",
    "    return a.reshape(28, 28)\n",
    "\n",
    "# ********** Display testing images **********\n",
    "print(\"n = \", end = '')\n",
    "n = int(input())\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.imshow(plot(x_test[n]), cmap = 'gray')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "category = {\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trousers',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandals',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneakers',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}\n",
    "### Print inference results corresponding to the images we plot\n",
    "prediction = model_test.predict(x_test[n].reshape(-1, 28, 28, 1))\n",
    "print(\"Inference label: {}\".format(category[np.argmax(prediction, axis = 1)[0]]))\n",
    "print(\"Ground truth label: {}\".format(category[np.argmax(y_test[n], axis = 0)])) \n",
    "    # y_test[n] is one-hot-encoded, use np.argmax to decode\n",
    "    \n",
    "# best val_accuracy: 93.08%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
