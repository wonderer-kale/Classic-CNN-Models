{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10_VGG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules Utilized in this Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10vgg:\n",
    "# Initial Function\n",
    "    def __init__(self, train = True):\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32, 32, 3]\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load('cifar10vgg.h5')\n",
    "            \n",
    "        \n",
    "# Model Architecture       \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "        \n",
    "        ## Block 1\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3, 3), \n",
    "                         padding = 'same', input_shape = self.x_shape, \n",
    "                         activation = 'relu', name = 'Conv2D_1-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_1-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 2\n",
    "        model.add(Conv2D(filters = 128, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_2-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        model.add(Conv2D(filters = 128, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_2-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 3\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 4\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "        ## Block 5\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        \n",
    "        ## Flatten & Dense\n",
    "        model.add(Flatten(name = 'Flatten'))\n",
    "        model.add(Dense(units = 512, activation = 'relu', name = 'fs',\n",
    "                        kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units = self.num_classes, activation = 'softmax',\n",
    "                        name = 'logit'))\n",
    "        \n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    \n",
    "\n",
    "# Data Normalization for Training\n",
    "    def normalize(self, X_train, X_test):\n",
    "        ## This function normalize inputs for zero mean and unit variance.\n",
    "        ## Input: training set and test set.\n",
    "        ## Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train, axis = (0, 1, 2, 3))\n",
    "        std = np.std(X_train, axis = (0, 1, 2, 3))\n",
    "        X_train = (X_train - mean) / (std + 1e-7)\n",
    "        X_test = (X_test - mean) / (std + 1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "\n",
    "# Data Normalization for Prediction\n",
    "    def normalize_production(self, x):\n",
    "        ## This function is used to normalize instances in production according to saved training set statistics.\n",
    "        ## Input: X - a training set.\n",
    "        ## Output X - a normalized training set according to normalization constants.\n",
    "        ## These values produced during first training and are general for the standard cifar10 training set normalization.\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x - mean) / (std + 1e-7)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Prediction\n",
    "    def predict(self, x, normalize = True, batch_size = 50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x, batch_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Train Model\n",
    "    def train(self, model):\n",
    "        ## Training Parameters\n",
    "        batch_size = 128\n",
    "        maxepochs = 50\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        ## The data, shuffled and split between train and test sets:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        ## Data Augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center = False,  ### set input mean to 0 over the dataset\n",
    "            samplewise_center = False,  ### set each sample mean to 0\n",
    "            featurewise_std_normalization = False,  ### divide inputs by std of the dataset\n",
    "            samplewise_std_normalization = False,  ### divide each input by its std\n",
    "            zca_whitening = False,  ### apply ZCA whitening\n",
    "            rotation_range = 15,  ### randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range = 0.1,  ### randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range = 0.1,  ### randomly shift images vertically (fraction of total height)\n",
    "            zoom_range = 0.1,\n",
    "            shear_range = 0.1,\n",
    "            horizontal_flip = True,  ### randomly flip images\n",
    "            vertical_flip = False)  ### randomly flip images\n",
    "        ## (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        ## Optimization Details\n",
    "        sgd = optimizers.SGD(lr = learning_rate, decay = lr_decay, momentum = 0.9, nesterov = True)\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "\n",
    "        ## Training process in a for loop with learning rate drop every 20 epochs.\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                                          steps_per_epoch = x_train.shape[0] // batch_size,\n",
    "                                          epochs = maxepochs, verbose = 1, shuffle = True,\n",
    "                                          validation_data = (x_test, y_test), \n",
    "                                          callbacks = [reduce_lr, ModelCheckpoint('cifar10vgg.h5',\n",
    "                                                                                  monitor = 'val_accuracy',\n",
    "                                                                                  save_best_only = True)])\n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1-1 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1-2 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2-1 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2-2 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-1 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-2 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-3 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-1 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-2 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-3 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-1 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-2 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-3 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fs (Dense)                   (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "logit (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,001,418\n",
      "Trainable params: 14,991,946\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "390/390 [==============================] - 1432s 4s/step - loss: 19.4156 - accuracy: 0.1892 - val_loss: 13.9775 - val_accuracy: 0.1429 - lr: 0.1000\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 1399s 4s/step - loss: 9.9410 - accuracy: 0.3082 - val_loss: 7.4977 - val_accuracy: 0.2200 - lr: 0.1000\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 1388s 4s/step - loss: 5.3975 - accuracy: 0.4077 - val_loss: 4.5658 - val_accuracy: 0.2689 - lr: 0.1000\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 1405s 4s/step - loss: 3.2790 - accuracy: 0.5060 - val_loss: 2.8186 - val_accuracy: 0.4889 - lr: 0.1000\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 1396s 4s/step - loss: 2.3131 - accuracy: 0.5713 - val_loss: 1.9119 - val_accuracy: 0.6307 - lr: 0.1000\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 1400s 4s/step - loss: 1.8280 - accuracy: 0.6184 - val_loss: 1.9434 - val_accuracy: 0.5564 - lr: 0.1000\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 1401s 4s/step - loss: 1.6227 - accuracy: 0.6487 - val_loss: 1.4408 - val_accuracy: 0.7041 - lr: 0.1000\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 1400s 4s/step - loss: 1.5405 - accuracy: 0.6659 - val_loss: 1.4222 - val_accuracy: 0.7014 - lr: 0.1000\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 1403s 4s/step - loss: 1.5083 - accuracy: 0.6836 - val_loss: 1.4787 - val_accuracy: 0.6962 - lr: 0.1000\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 1398s 4s/step - loss: 1.4884 - accuracy: 0.6935 - val_loss: 1.4300 - val_accuracy: 0.7090 - lr: 0.1000\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 1398s 4s/step - loss: 1.4701 - accuracy: 0.7058 - val_loss: 1.3879 - val_accuracy: 0.7277 - lr: 0.1000\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 1396s 4s/step - loss: 1.4641 - accuracy: 0.7105 - val_loss: 1.4690 - val_accuracy: 0.7190 - lr: 0.1000\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 1398s 4s/step - loss: 1.4619 - accuracy: 0.7164 - val_loss: 1.3521 - val_accuracy: 0.7565 - lr: 0.1000\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 1392s 4s/step - loss: 1.4685 - accuracy: 0.7211 - val_loss: 1.5081 - val_accuracy: 0.7114 - lr: 0.1000\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 1399s 4s/step - loss: 1.4717 - accuracy: 0.7266 - val_loss: 1.4626 - val_accuracy: 0.7280 - lr: 0.1000\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 1395s 4s/step - loss: 1.4823 - accuracy: 0.7292 - val_loss: 1.4026 - val_accuracy: 0.7577 - lr: 0.1000\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 1401s 4s/step - loss: 1.4846 - accuracy: 0.7338 - val_loss: 1.6290 - val_accuracy: 0.7026 - lr: 0.1000\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 1393s 4s/step - loss: 1.4880 - accuracy: 0.7373 - val_loss: 1.4195 - val_accuracy: 0.7513 - lr: 0.1000\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 1400s 4s/step - loss: 1.4925 - accuracy: 0.7361 - val_loss: 1.3465 - val_accuracy: 0.7845 - lr: 0.1000\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 1397s 4s/step - loss: 1.5013 - accuracy: 0.7387 - val_loss: 1.3641 - val_accuracy: 0.7808 - lr: 0.1000\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 1391s 4s/step - loss: 1.3274 - accuracy: 0.7803 - val_loss: 1.1584 - val_accuracy: 0.8177 - lr: 0.0500\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 1397s 4s/step - loss: 1.2269 - accuracy: 0.7890 - val_loss: 1.1276 - val_accuracy: 0.8111 - lr: 0.0500\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 1394s 4s/step - loss: 1.2008 - accuracy: 0.7890 - val_loss: 1.0570 - val_accuracy: 0.8314 - lr: 0.0500\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 1397s 4s/step - loss: 1.1991 - accuracy: 0.7874 - val_loss: 1.0906 - val_accuracy: 0.8172 - lr: 0.0500\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 1515s 4s/step - loss: 1.1970 - accuracy: 0.7892 - val_loss: 1.1325 - val_accuracy: 0.8072 - lr: 0.0500\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 1514s 4s/step - loss: 1.1968 - accuracy: 0.7913 - val_loss: 1.1211 - val_accuracy: 0.8177 - lr: 0.0500\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 1384s 4s/step - loss: 1.1961 - accuracy: 0.7939 - val_loss: 1.0957 - val_accuracy: 0.8252 - lr: 0.0500\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 1380s 4s/step - loss: 1.2015 - accuracy: 0.7948 - val_loss: 1.1251 - val_accuracy: 0.8198 - lr: 0.0500\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 1419s 4s/step - loss: 1.2073 - accuracy: 0.7933 - val_loss: 1.1866 - val_accuracy: 0.8021 - lr: 0.0500\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 1377s 4s/step - loss: 1.2153 - accuracy: 0.7938 - val_loss: 1.0623 - val_accuracy: 0.8395 - lr: 0.0500\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 1343s 3s/step - loss: 1.2094 - accuracy: 0.7971 - val_loss: 1.1257 - val_accuracy: 0.8225 - lr: 0.0500\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 1348s 3s/step - loss: 1.2150 - accuracy: 0.7967 - val_loss: 1.1051 - val_accuracy: 0.8328 - lr: 0.0500\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 1355s 3s/step - loss: 1.2208 - accuracy: 0.7950 - val_loss: 1.1295 - val_accuracy: 0.8263 - lr: 0.0500\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 1388s 4s/step - loss: 1.2169 - accuracy: 0.8004 - val_loss: 1.1321 - val_accuracy: 0.8269 - lr: 0.0500\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 1469s 4s/step - loss: 1.2181 - accuracy: 0.8009 - val_loss: 1.1927 - val_accuracy: 0.8114 - lr: 0.0500\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 1511s 4s/step - loss: 1.2206 - accuracy: 0.8003 - val_loss: 1.1999 - val_accuracy: 0.8038 - lr: 0.0500\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 1390s 4s/step - loss: 1.2309 - accuracy: 0.7976 - val_loss: 1.2129 - val_accuracy: 0.8113 - lr: 0.0500\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 1388s 4s/step - loss: 1.2232 - accuracy: 0.8032 - val_loss: 1.2126 - val_accuracy: 0.8105 - lr: 0.0500\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 1388s 4s/step - loss: 1.2316 - accuracy: 0.8005 - val_loss: 1.1919 - val_accuracy: 0.8133 - lr: 0.0500\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 1388s 4s/step - loss: 1.2261 - accuracy: 0.8057 - val_loss: 1.1772 - val_accuracy: 0.8148 - lr: 0.0500\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 1387s 4s/step - loss: 1.1047 - accuracy: 0.8360 - val_loss: 1.0123 - val_accuracy: 0.8583 - lr: 0.0250\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 1387s 4s/step - loss: 1.0238 - accuracy: 0.8445 - val_loss: 1.0169 - val_accuracy: 0.8428 - lr: 0.0250\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 1395s 4s/step - loss: 0.9972 - accuracy: 0.8454 - val_loss: 0.9738 - val_accuracy: 0.8483 - lr: 0.0250\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 1392s 4s/step - loss: 0.9798 - accuracy: 0.8438 - val_loss: 0.9285 - val_accuracy: 0.8593 - lr: 0.0250\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 1386s 4s/step - loss: 0.9722 - accuracy: 0.8436 - val_loss: 0.8872 - val_accuracy: 0.8705 - lr: 0.0250\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 1383s 4s/step - loss: 0.9659 - accuracy: 0.8460 - val_loss: 0.9437 - val_accuracy: 0.8525 - lr: 0.0250\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 1382s 4s/step - loss: 0.9628 - accuracy: 0.8440 - val_loss: 0.8840 - val_accuracy: 0.8691 - lr: 0.0250\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 1384s 4s/step - loss: 0.9569 - accuracy: 0.8457 - val_loss: 0.8972 - val_accuracy: 0.8669 - lr: 0.0250\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 1381s 4s/step - loss: 0.9593 - accuracy: 0.8445 - val_loss: 0.8954 - val_accuracy: 0.8670 - lr: 0.0250\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 1381s 4s/step - loss: 0.9546 - accuracy: 0.8473 - val_loss: 0.9019 - val_accuracy: 0.8647 - lr: 0.0250\n",
      "the validation 0/1 loss is:  0.8408\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    model_current = cifar10vgg()\n",
    "    model_best = load_model('cifar10vgg.h5')\n",
    "\n",
    "    predicted_x = model_best.predict(x_test)\n",
    "    residuals = np.argmax(predicted_x, 1) != np.argmax(y_test, 1)\n",
    "\n",
    "    loss = sum(residuals) / len(residuals)\n",
    "    print(\"the validation 0/1 loss is: \", loss)\n",
    "\n",
    "# first time performance\n",
    "# 82.65%\n",
    "# trained for about 10 hours\n",
    "\n",
    "# second time performance (maxepochs: 25 -> 50, zoom_range and shear_range added)\n",
    "# 87.05%\n",
    "# trained for about 20 hours\n",
    "\n",
    "# parameters: 15,001,418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Selected Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 7663\n",
      "Inference label: bird\n",
      "Ground truth label: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Plot testing data\n",
    "def plot(a):\n",
    "    a = a.astype(np.uint8)\n",
    "    return a.reshape(32, 32, 3)\n",
    "\n",
    "# ********** Display testing images **********\n",
    "print(\"n = \", end = '')\n",
    "n = int(input())\n",
    "ax = plt.subplot()\n",
    "plt.imshow(plot(x_test[n]), cmap = None)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "category = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "model_test = load_model('cifar10vgg.h5') \n",
    "x_test = x_test.astype('float32')\n",
    "mean = 120.707\n",
    "std = 64.15\n",
    "x_test = (x_test - mean) / (std + 1e-7)\n",
    "### Print inference results corresponding to the image we plot\n",
    "prediction = model_test.predict(x_test[n].reshape(-1, 32, 32, 3))\n",
    "print(\"Inference label: {}\".format(category[np.argmax(prediction, axis = 1)[0]]))\n",
    "print(\"Ground truth label: {}\".format(category[np.argmax(y_test[n], axis = 0)])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
