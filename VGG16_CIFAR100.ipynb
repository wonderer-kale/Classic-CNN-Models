{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100_VGG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules Utilized in this Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.datasets import cifar100\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar100vgg:\n",
    "# Initial Function\n",
    "    def __init__(self, train = True):\n",
    "        self.num_classes = 100\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32, 32, 3]\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "            self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load('cifar100vgg.h5')\n",
    "            \n",
    "        \n",
    "# Model Architecture       \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "        \n",
    "        ## Block 1\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3, 3), \n",
    "                         padding = 'same', input_shape = self.x_shape, \n",
    "                         activation = 'relu', name = 'Conv2D_1-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_1-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 2\n",
    "        model.add(Conv2D(filters = 128, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_2-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        model.add(Conv2D(filters = 128, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_2-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 3\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_3-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "        \n",
    "        ## Block 4\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_4-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "        ## Block 5\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-1',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-2',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(filters = 512, kernel_size = (3, 3), \n",
    "                         padding = 'same', activation = 'relu', name = 'Conv2D_5-3',\n",
    "                         kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        \n",
    "        ## Flatten & Dense\n",
    "        model.add(Flatten(name = 'Flatten'))\n",
    "        model.add(Dense(units = 512, activation = 'relu', name = 'fs',\n",
    "                        kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units = self.num_classes, activation = 'softmax',\n",
    "                        name = 'logit'))\n",
    "        \n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    \n",
    "\n",
    "# Data Normalization for Training\n",
    "    def normalize(self, X_train, X_test):\n",
    "        ## This function normalize inputs for zero mean and unit variance.\n",
    "        ## Input: training set and test set.\n",
    "        ## Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train, axis = (0, 1, 2, 3))\n",
    "        std = np.std(X_train, axis = (0, 1, 2, 3))\n",
    "        X_train = (X_train - mean) / (std + 1e-7)\n",
    "        X_test = (X_test - mean) / (std + 1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "\n",
    "# Data Normalization for Prediction\n",
    "    def normalize_production(self, x):\n",
    "        ## This function is used to normalize instances in production according to saved training set statistics.\n",
    "        ## Input: X - a training set.\n",
    "        ## Output X - a normalized training set according to normalization constants.\n",
    "        ## These values produced during first training and are general for the standard cifar100 training set normalization.\n",
    "        mean = 121.936\n",
    "        std = 68.389\n",
    "        return (x - mean) / (std + 1e-7)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Prediction\n",
    "    def predict(self, x, normalize = True, batch_size = 50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x, batch_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Train Model\n",
    "    def train(self, model):\n",
    "        ## Training Parameters\n",
    "        batch_size = 128\n",
    "        maxepochs = 50\n",
    "        learning_rate = 0.1\n",
    "        lr_decay = 1e-6\n",
    "        lr_drop = 20\n",
    "        ## The data, shuffled and split between train and test sets:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train, x_test = self.normalize(x_train, x_test)\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "        def lr_scheduler(epoch):\n",
    "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        ## Data Augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center = False,  ### set input mean to 0 over the dataset\n",
    "            samplewise_center = False,  ### set each sample mean to 0\n",
    "            featurewise_std_normalization = False,  ### divide inputs by std of the dataset\n",
    "            samplewise_std_normalization = False,  ### divide each input by its std\n",
    "            zca_whitening = False,  ### apply ZCA whitening\n",
    "            rotation_range = 15,  ### randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range = 0.1,  ### randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range = 0.1,  ### randomly shift images vertically (fraction of total height)\n",
    "            zoom_range = 0.1,\n",
    "            shear_range = 0.1,\n",
    "            horizontal_flip = True,  ### randomly flip images\n",
    "            vertical_flip = False)  ### randomly flip images\n",
    "        ## (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        ## Optimization Details\n",
    "        sgd = optimizers.SGD(lr = learning_rate, decay = lr_decay, momentum = 0.9, nesterov = True)\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "\n",
    "        ## Training process in a for loop with learning rate drop every 20 epochs.\n",
    "        historytemp = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                                          steps_per_epoch = x_train.shape[0] // batch_size,\n",
    "                                          epochs = maxepochs, verbose = 1, shuffle = True,\n",
    "                                          validation_data = (x_test, y_test), \n",
    "                                          callbacks = [reduce_lr, ModelCheckpoint('cifar100vgg.h5',\n",
    "                                                                                  monitor = 'val_accuracy',\n",
    "                                                                                  save_best_only = True)])\n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1-1 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1-2 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2-1 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2-2 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-1 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-2 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_3-3 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-1 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-2 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4-3 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-1 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-2 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_5-3 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fs (Dense)                   (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "logit (Dense)                (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 15,047,588\n",
      "Trainable params: 15,038,116\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-6-14279c29a084>:205: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-14279c29a084>:205: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - 1480s 4s/step - loss: 19.5891 - accuracy: 0.0281 - val_loss: 15.4745 - val_accuracy: 0.0104 - lr: 0.1000\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 1527s 4s/step - loss: 11.2782 - accuracy: 0.0451 - val_loss: 9.6257 - val_accuracy: 0.0138 - lr: 0.1000\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 1506s 4s/step - loss: 7.3589 - accuracy: 0.0627 - val_loss: 6.8694 - val_accuracy: 0.0297 - lr: 0.1000\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 1488s 4s/step - loss: 5.5833 - accuracy: 0.0702 - val_loss: 5.4340 - val_accuracy: 0.0471 - lr: 0.1000\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 1443s 4s/step - loss: 4.7472 - accuracy: 0.0841 - val_loss: 4.6801 - val_accuracy: 0.0729 - lr: 0.1000\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 1423s 4s/step - loss: 4.3488 - accuracy: 0.1009 - val_loss: 4.3005 - val_accuracy: 0.1127 - lr: 0.1000\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 1381s 4s/step - loss: 4.1259 - accuracy: 0.1208 - val_loss: 4.0667 - val_accuracy: 0.1361 - lr: 0.1000\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 1375s 4s/step - loss: 3.9918 - accuracy: 0.1418 - val_loss: 3.8830 - val_accuracy: 0.1590 - lr: 0.1000\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 1375s 4s/step - loss: 3.9153 - accuracy: 0.1633 - val_loss: 3.8065 - val_accuracy: 0.1884 - lr: 0.1000\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 1392s 4s/step - loss: 3.8165 - accuracy: 0.1948 - val_loss: 3.7999 - val_accuracy: 0.2145 - lr: 0.1000\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 1397s 4s/step - loss: 3.7621 - accuracy: 0.2225 - val_loss: 3.5904 - val_accuracy: 0.2551 - lr: 0.1000\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 1405s 4s/step - loss: 3.7345 - accuracy: 0.2406 - val_loss: 3.6021 - val_accuracy: 0.2774 - lr: 0.1000\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 1398s 4s/step - loss: 3.7164 - accuracy: 0.2570 - val_loss: 3.4823 - val_accuracy: 0.3048 - lr: 0.1000\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 1406s 4s/step - loss: 3.7071 - accuracy: 0.2703 - val_loss: 3.6399 - val_accuracy: 0.2934 - lr: 0.1000\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 1402s 4s/step - loss: 3.7292 - accuracy: 0.2779 - val_loss: 3.6325 - val_accuracy: 0.3125 - lr: 0.1000\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 1397s 4s/step - loss: 3.7388 - accuracy: 0.2906 - val_loss: 3.7454 - val_accuracy: 0.3081 - lr: 0.1000\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 1402s 4s/step - loss: 3.7486 - accuracy: 0.2999 - val_loss: 3.7550 - val_accuracy: 0.3227 - lr: 0.1000\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 1408s 4s/step - loss: 3.7674 - accuracy: 0.3085 - val_loss: 3.6714 - val_accuracy: 0.3303 - lr: 0.1000\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 1400s 4s/step - loss: 3.7749 - accuracy: 0.3139 - val_loss: 3.6697 - val_accuracy: 0.3497 - lr: 0.1000\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 1409s 4s/step - loss: 3.7899 - accuracy: 0.3182 - val_loss: 3.7883 - val_accuracy: 0.3473 - lr: 0.1000\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 1402s 4s/step - loss: 3.4625 - accuracy: 0.3773 - val_loss: 3.3079 - val_accuracy: 0.4003 - lr: 0.0500\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 1406s 4s/step - loss: 3.3187 - accuracy: 0.3903 - val_loss: 3.2623 - val_accuracy: 0.4024 - lr: 0.0500\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 1409s 4s/step - loss: 3.2716 - accuracy: 0.3936 - val_loss: 3.0793 - val_accuracy: 0.4336 - lr: 0.0500\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 1401s 4s/step - loss: 3.2612 - accuracy: 0.4009 - val_loss: 3.1155 - val_accuracy: 0.4338 - lr: 0.0500\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 1408s 4s/step - loss: 3.2564 - accuracy: 0.4048 - val_loss: 3.4220 - val_accuracy: 0.3970 - lr: 0.0500\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 1406s 4s/step - loss: 3.2740 - accuracy: 0.4088 - val_loss: 3.2318 - val_accuracy: 0.4385 - lr: 0.0500\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 1409s 4s/step - loss: 3.2889 - accuracy: 0.4119 - val_loss: 3.1082 - val_accuracy: 0.4625 - lr: 0.0500\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 1372s 4s/step - loss: 3.2882 - accuracy: 0.4170 - val_loss: 3.2365 - val_accuracy: 0.4373 - lr: 0.0500\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 1439s 4s/step - loss: 3.2899 - accuracy: 0.4232 - val_loss: 3.0971 - val_accuracy: 0.4614 - lr: 0.0500\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 1385s 4s/step - loss: 3.2991 - accuracy: 0.4279 - val_loss: 3.2974 - val_accuracy: 0.4472 - lr: 0.0500\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 1383s 4s/step - loss: 3.3071 - accuracy: 0.4299 - val_loss: 3.1828 - val_accuracy: 0.4691 - lr: 0.0500\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 1384s 4s/step - loss: 3.3096 - accuracy: 0.4355 - val_loss: 3.3124 - val_accuracy: 0.4446 - lr: 0.0500\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 1386s 4s/step - loss: 3.3193 - accuracy: 0.4358 - val_loss: 3.3487 - val_accuracy: 0.4409 - lr: 0.0500\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 1480s 4s/step - loss: 3.3236 - accuracy: 0.4420 - val_loss: 3.2514 - val_accuracy: 0.4707 - lr: 0.0500\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 1546s 4s/step - loss: 3.3303 - accuracy: 0.4457 - val_loss: 3.5388 - val_accuracy: 0.4253 - lr: 0.0500\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 1535s 4s/step - loss: 3.3344 - accuracy: 0.4453 - val_loss: 3.2812 - val_accuracy: 0.4658 - lr: 0.0500\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 1427s 4s/step - loss: 3.3336 - accuracy: 0.4481 - val_loss: 3.2516 - val_accuracy: 0.4739 - lr: 0.0500\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 1322s 3s/step - loss: 3.3331 - accuracy: 0.4502 - val_loss: 3.5070 - val_accuracy: 0.4490 - lr: 0.0500\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 1346s 3s/step - loss: 3.3416 - accuracy: 0.4521 - val_loss: 3.3333 - val_accuracy: 0.4678 - lr: 0.0500\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 1368s 4s/step - loss: 3.3431 - accuracy: 0.4533 - val_loss: 3.3589 - val_accuracy: 0.4625 - lr: 0.0500\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 1447s 4s/step - loss: 3.0771 - accuracy: 0.5051 - val_loss: 3.0863 - val_accuracy: 0.5072 - lr: 0.0250\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 1439s 4s/step - loss: 2.9294 - accuracy: 0.5230 - val_loss: 2.8480 - val_accuracy: 0.5337 - lr: 0.0250\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 1403s 4s/step - loss: 2.8657 - accuracy: 0.5248 - val_loss: 2.7494 - val_accuracy: 0.5474 - lr: 0.0250\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 1417s 4s/step - loss: 2.8276 - accuracy: 0.5271 - val_loss: 2.7972 - val_accuracy: 0.5402 - lr: 0.0250\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 1391s 4s/step - loss: 2.8216 - accuracy: 0.5244 - val_loss: 2.8357 - val_accuracy: 0.5312 - lr: 0.0250\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 1377s 4s/step - loss: 2.8009 - accuracy: 0.5303 - val_loss: 2.7114 - val_accuracy: 0.5527 - lr: 0.0250\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 1385s 4s/step - loss: 2.7920 - accuracy: 0.5315 - val_loss: 2.7055 - val_accuracy: 0.5571 - lr: 0.0250\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 1425s 4s/step - loss: 2.7984 - accuracy: 0.5305 - val_loss: 2.8386 - val_accuracy: 0.5356 - lr: 0.0250\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 1431s 4s/step - loss: 2.8121 - accuracy: 0.5309 - val_loss: 2.8569 - val_accuracy: 0.5308 - lr: 0.0250\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 1407s 4s/step - loss: 2.8000 - accuracy: 0.5353 - val_loss: 2.8975 - val_accuracy: 0.5323 - lr: 0.0250\n",
      "the validation 0/1 loss is:  0.9741\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = keras.utils.to_categorical(y_train, 100)\n",
    "    y_test = keras.utils.to_categorical(y_test, 100)\n",
    "\n",
    "    model_current = cifar100vgg()\n",
    "    model_best = load_model('cifar100vgg.h5')\n",
    "\n",
    "    predicted_x = model_best.predict(x_test)\n",
    "    residuals = np.argmax(predicted_x, 1) != np.argmax(y_test, 1)\n",
    "\n",
    "    loss = sum(residuals) / len(residuals)\n",
    "    print(\"the validation 0/1 loss is: \", loss)\n",
    "    \n",
    "# first time performance\n",
    "# 44.63%\n",
    "# trained for about 9.7 hours\n",
    "\n",
    "# second time performance (maxepochs: 25 -> 50, zoom_range and shear_range added)\n",
    "# 55.71%\n",
    "# trained for about 20 hours\n",
    "\n",
    "# parameters: 15,047,588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Selected Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 9\n",
      "Inference label: apple\n",
      "Ground truth label: apple\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import load_model\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Plot testing data\n",
    "def plot(a):\n",
    "    a = a.astype(np.uint8)\n",
    "    return a.reshape(32, 32, 3)\n",
    "\n",
    "# ********** Display testing images **********\n",
    "print(\"n = \", end = '')\n",
    "n = int(input())\n",
    "ax = plt.subplot()\n",
    "plt.imshow(plot(x_test[n]), cmap = None)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n",
    "model_test = load_model('cifar100vgg.h5') \n",
    "x_test = x_test.astype('float32')\n",
    "mean = 120.707\n",
    "std = 64.15\n",
    "x_test[n] = (x_test[n] - mean) / (std + 1e-7)\n",
    "category = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]\n",
    "### Print inference results corresponding to the image we plot\n",
    "prediction = model_test.predict(x_test[n].reshape(-1, 32, 32, 3))\n",
    "print(\"Inference label: {}\".format(category[np.argmax(prediction, axis = 1)[0]]))\n",
    "print(\"Ground truth label: {}\".format(category[np.argmax(y_test[n], axis = 0)])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
